{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKHY1cyNbNe0XqENUIo8t8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gru97/DeepLearningCourse/blob/main/session5_excercise_lenet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lhuAdxjU2Lrh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device='cpu'\n",
        "\n",
        "train_dataset= datasets.CIFAR10('/content/', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset= datasets.CIFAR10('/content/', train=False, download=True, transform=transforms.ToTensor())\n",
        "train_x= train_dataset.data\n",
        "train_y=train_dataset.targets\n",
        "\n",
        "test_x= test_dataset.data\n",
        "trest_y= test_dataset.targets"
      ],
      "metadata": {
        "id": "2AuXecYc2-jP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28651a92-7cdb-444a-e1a5-4df412eb548d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.Tensor(train_x).shape)\n",
        "torch.Tensor(train_x).permute(0, 3, 1, 2).shape  # Rearrange to (N, C, H, W).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ4gBoUzcCFc",
        "outputId": "e673d081-5fa4-4d77-e582-800c4fea6289"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000, 32, 32, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape) #(50000, 32, 32, 3)\n",
        "#print(train_y.shape) #[50000])\n",
        "print(train_x[0].shape) #(32, 32, 3) image\n",
        "#print(train_y.unique()) #[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "train_dataset.classes"
      ],
      "metadata": {
        "id": "LyDmyQdBSASr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0b7b66-9e9f-4a2f-f013-d2c4b45816f7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(32, 32, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class Lenet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1= nn.Conv2d(3,6,5)  # 1= grey, 6= number of filters 5= size of filter (32-28+1=5)\n",
        "    self.pool1= nn.MaxPool2d(2) # 28 has turned 14 so MaxPool(2)\n",
        "    self.conv2= nn.Conv2d(6,16,5) # 6 previous filters result in 6 channel features maps, 16 filters in this step, 10-14+1=5 size of filter\n",
        "    self.pool2=nn.MaxPool2d(2)\n",
        "    self.flatten=nn.Flatten()\n",
        "    self.fc1=nn.Linear(16*5*5,120)\n",
        "    self.fc2=nn.Linear(120,84)\n",
        "    self.fc3=nn.Linear(84,10)\n",
        "    self.relu= nn.ReLU()\n",
        "\n",
        "  def featurize(self, x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.pool1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=self.pool2(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.flatten(x)\n",
        "    return x\n",
        "  def classifier(self, x):\n",
        "    x= self.fc1(x)\n",
        "    x= self.relu(x)\n",
        "    x= self.fc2(x)\n",
        "    x= self.relu(x)\n",
        "    x=self.fc3(x)\n",
        "    return x\n",
        "  def forward(self, x):\n",
        "    x= self.featurize(x)\n",
        "    x= self.classifier(x)\n",
        "    return x;"
      ],
      "metadata": {
        "id": "P86ou1s-fUjr"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, target):\n",
        "    self.data = torch.tensor(data, dtype=torch.float32)/255\n",
        "    self.data= self.data.permute(0, 3, 1, 2)  # Rearrange to (N, C, H, W)\n",
        "    self.target=torch.tensor(target)\n",
        "  def __getitem__(self, id):\n",
        "    return self.data[id], self.target[id]\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "TbNGKbey3C-V"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "train_dataset= CustomDataset(train_x , train_y)\n",
        "validation_dataset= CustomDataset(test_x, trest_y)\n",
        "train_dataset.__len__()\n",
        "train_dataset.__len__()/batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOzFPpGp3Efb",
        "outputId": "a61fb807-5b07-4c4a-896a-1515642b917f"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1562.5"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader= DataLoader(train_dataset,batch_size, shuffle=True)\n",
        "test_dataloader= DataLoader(validation_dataset, batch_size, shuffle=True)\n",
        "len(train_dataloader)  #len/batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EuBBbG53F_8",
        "outputId": "efd10018-e591-41da-865d-74e5069fac2f"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1563"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, targets):\n",
        "  _, predictions = torch.max(output, 1)  # class labels of max possiblitity resulted from a neuron\n",
        "\n",
        "  correct= (predictions==targets).sum().item()\n",
        "  return correct/targets.size(0)"
      ],
      "metadata": {
        "id": "wVENEbazfwuk"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.1\n",
        "model= Lenet5().to(device)\n",
        "optimizer= torch.optim.SGD(model.parameters(), lr= lr)\n",
        "loss_function= nn.CrossEntropyLoss()  # for multi class data\n",
        "\n",
        "def train(model, dataloader, loss_function, optimizer):\n",
        "  total_loss=0.0\n",
        "  total_acc=0.0\n",
        "  for inputs, targets in dataloader:  # len(dataloader)/batch_size = count for\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    model.train()\n",
        "    outputs = model(inputs)\n",
        "    loss_of_a_batch = loss_function(outputs,targets)\n",
        "    loss_of_a_batch.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss += loss_of_a_batch.item()\n",
        "    total_acc += accuracy(outputs,targets)\n",
        "  return total_loss/len(dataloader), total_acc/len(dataloader)  #mean in every epoch\n",
        "\n",
        "def validate(model, dataloader, loss_function):\n",
        "    model.eval()\n",
        "    total_loss=0.0\n",
        "    total_acc=0.0\n",
        "    with torch.no_grad():\n",
        "      for inputs, targets in dataloader:\n",
        "        inputs, targets= inputs.to(device), targets.to(device)\n",
        "        outputs= model(inputs)\n",
        "        loss= loss_function(outputs,targets)\n",
        "        total_loss += loss.item()\n",
        "        total_acc += accuracy(outputs,targets)\n",
        "    return total_loss/len(dataloader), total_acc/len(dataloader)  #mean in every epoch\n",
        "\n"
      ],
      "metadata": {
        "id": "noFUrxzG3JO1"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch=30\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "train_acc=[]\n",
        "test_acc=[]\n",
        "for i in range(epoch):\n",
        "    train_loss, train_accuracy = train(model, train_dataloader, loss_function, optimizer)\n",
        "    train_losses.append(train_loss)\n",
        "    train_acc.append(train_accuracy)\n",
        "    test_loss, test_accuracy =validate(model, test_dataloader, loss_function)\n",
        "    test_losses.append(test_loss)\n",
        "    test_acc.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {i+1}/{epoch}, train_loss: {train_loss}, test_loss: {test_loss}, train_acc: {train_accuracy}, test_acc: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpmDgA6SsRqv",
        "outputId": "dac8d09c-d59c-4280-fc3e-af444367f66d"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, train_loss: 1.930863979071741, test_loss: 1.729329214309351, train_acc: 0.29168666026871404, test_acc: 0.36461661341853036\n",
            "Epoch 2/30, train_loss: 1.5359826193203625, test_loss: 1.4077651239812565, train_acc: 0.44629718490083176, test_acc: 0.4902156549520767\n",
            "Epoch 3/30, train_loss: 1.4028550135883397, test_loss: 1.4104589979869488, train_acc: 0.4950615802943058, test_acc: 0.49490814696485624\n",
            "Epoch 4/30, train_loss: 1.3155863973778634, test_loss: 1.357848939423363, train_acc: 0.5286708253358925, test_acc: 0.5160742811501597\n",
            "Epoch 5/30, train_loss: 1.2399904592557358, test_loss: 1.3110644842108217, train_acc: 0.5558221369161869, test_acc: 0.5396365814696485\n",
            "Epoch 6/30, train_loss: 1.1870032343739358, test_loss: 1.3767601015468756, train_acc: 0.5787547984644914, test_acc: 0.5296525559105432\n",
            "Epoch 7/30, train_loss: 1.134631172289699, test_loss: 1.2873598579019785, train_acc: 0.5965690978886756, test_acc: 0.5470247603833865\n",
            "Epoch 8/30, train_loss: 1.0939206736101528, test_loss: 1.272014360267895, train_acc: 0.6109644913627639, test_acc: 0.5652955271565495\n",
            "Epoch 9/30, train_loss: 1.0606154170428341, test_loss: 1.2808401887409222, train_acc: 0.6231605886116443, test_acc: 0.560702875399361\n",
            "Epoch 10/30, train_loss: 1.0309963106003162, test_loss: 1.264979913021429, train_acc: 0.6359365003198977, test_acc: 0.5656948881789138\n",
            "Epoch 11/30, train_loss: 1.0042959160707123, test_loss: 1.3072058196646719, train_acc: 0.645233525271913, test_acc: 0.5509185303514377\n",
            "Epoch 12/30, train_loss: 0.9826650727046886, test_loss: 1.311089158439027, train_acc: 0.6547304862444018, test_acc: 0.5665934504792333\n",
            "Epoch 13/30, train_loss: 0.9594791265954136, test_loss: 1.3386025680139804, train_acc: 0.6607685540627, test_acc: 0.5559105431309904\n",
            "Epoch 14/30, train_loss: 0.9464562212093778, test_loss: 1.3275834942778078, train_acc: 0.6648672424824056, test_acc: 0.5729832268370607\n",
            "Epoch 15/30, train_loss: 0.9325835476185523, test_loss: 1.4962036832452963, train_acc: 0.6685060780550224, test_acc: 0.5448282747603834\n",
            "Epoch 16/30, train_loss: 0.9150367388912903, test_loss: 1.3300761342429506, train_acc: 0.6764435380678183, test_acc: 0.5702875399361023\n",
            "Epoch 17/30, train_loss: 0.9025091989369859, test_loss: 1.3965155289957698, train_acc: 0.6830614203454894, test_acc: 0.5566094249201278\n",
            "Epoch 18/30, train_loss: 0.8932137122462365, test_loss: 1.4128385445180411, train_acc: 0.6856206014075495, test_acc: 0.5630990415335463\n",
            "Epoch 19/30, train_loss: 0.8802559290150382, test_loss: 1.4049785956026266, train_acc: 0.6894193857965452, test_acc: 0.5633985623003195\n",
            "Epoch 20/30, train_loss: 0.8776530922031219, test_loss: 1.374194216042662, train_acc: 0.6913587651951375, test_acc: 0.5744808306709265\n",
            "Epoch 21/30, train_loss: 0.8654967924950601, test_loss: 1.3817352915343386, train_acc: 0.696777031349968, test_acc: 0.5556110223642172\n",
            "Epoch 22/30, train_loss: 0.863692910756656, test_loss: 1.7081862689968876, train_acc: 0.6953574856046065, test_acc: 0.5223642172523961\n",
            "Epoch 23/30, train_loss: 0.849428004434455, test_loss: 1.5164711555352988, train_acc: 0.7023752399232246, test_acc: 0.5443290734824281\n",
            "Epoch 24/30, train_loss: 0.8456800412422407, test_loss: 1.613467269621718, train_acc: 0.7033549264235445, test_acc: 0.549620607028754\n",
            "Epoch 25/30, train_loss: 0.836304294952428, test_loss: 1.5003104790711936, train_acc: 0.7066538707613563, test_acc: 0.5627995207667732\n",
            "Epoch 26/30, train_loss: 0.8383496558711991, test_loss: 1.5528033720418668, train_acc: 0.7069337811900192, test_acc: 0.5464257188498403\n",
            "Epoch 27/30, train_loss: 0.8374527766204232, test_loss: 1.4872754250471585, train_acc: 0.707093730006398, test_acc: 0.5604033546325878\n",
            "Epoch 28/30, train_loss: 0.8298048376655701, test_loss: 1.5449351731199807, train_acc: 0.7098728406909789, test_acc: 0.5411341853035144\n",
            "Epoch 29/30, train_loss: 0.8279202487403128, test_loss: 1.6146331048621156, train_acc: 0.7117322456813819, test_acc: 0.5412340255591054\n",
            "Epoch 30/30, train_loss: 0.8276008042439542, test_loss: 1.560126557136877, train_acc: 0.7137715930902111, test_acc: 0.5591054313099042\n"
          ]
        }
      ]
    }
  ]
}